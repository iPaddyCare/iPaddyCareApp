{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "53d083fb"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8288a58d",
        "outputId": "a9f03dd9-9071-441c-d48d-642f78b8eeb1"
      },
      "source": [
        "import kagglehub\n",
        "\n",
        "path = kagglehub.dataset_download(\"imbikramsaha/paddy-doctor\")\n",
        "print(\"Dataset path:\", path)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/imbikramsaha/paddy-doctor?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.02G/1.02G [00:25<00:00, 42.7MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset path: /root/.cache/kagglehub/datasets/imbikramsaha/paddy-doctor/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /root/.cache/kagglehub/datasets/imbikramsaha/paddy-doctor/versions/1/paddy-disease-classification\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqjVsQS-spWo",
        "outputId": "91d97b26-c2d6-4b58-8359-b089034eb95b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_submission.csv  test_images  train.csv  train_images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ee4bb33"
      },
      "source": [
        "dataset_root_path = os.path.join(path, 'paddy-disease-classification')\n",
        "train_csv_path = os.path.join(dataset_root_path, 'train.csv')\n",
        "train_images_path = os.path.join(dataset_root_path, 'train_images')\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57ab336d"
      },
      "source": [
        "full_df = pd.read_csv(train_csv_path)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(full_df.columns)\n"
      ],
      "metadata": {
        "id": "jZVDbUHaP-QJ",
        "outputId": "02a91e0c-d5d5-4a30-a2cb-d53eb4d2a02b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['image_id', 'label', 'variety', 'age'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = sorted(full_df[\"label\"].unique())\n",
        "print(labels)\n"
      ],
      "metadata": {
        "id": "l453HTAfQEQn",
        "outputId": "7152e937-c3e4-4317-c49d-0ab89823ae9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['bacterial_leaf_blight', 'bacterial_leaf_streak', 'bacterial_panicle_blight', 'blast', 'brown_spot', 'dead_heart', 'downy_mildew', 'hispa', 'normal', 'tungro']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "dataset_path = \"/kaggle/input/paddy-doctor\"\n",
        "\n",
        "for root, dirs, files in os.walk(dataset_path):\n",
        "    level = root.replace(dataset_path, '').count(os.sep)\n",
        "    indent = ' ' * 4 * level\n",
        "    print(f\"{indent}{os.path.basename(root)}/\")\n",
        "    subindent = ' ' * 4 * (level + 1)\n",
        "    for f in files[:5]:  # only first 5 files\n",
        "        print(f\"{subindent}{f}\")\n"
      ],
      "metadata": {
        "id": "Zh8HWO4VUSep"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f96a8081",
        "outputId": "bcb2c27f-1668-4102-d6a4-6cf39635a557"
      },
      "source": [
        "train_df, val_df = train_test_split(\n",
        "    full_df,\n",
        "    test_size=0.1,\n",
        "    stratify=full_df['label'],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(len(train_df), len(val_df))\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9366 1041\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "label_counts = train_df['label'].value_counts()\n",
        "label_order = sorted(train_df['label'].unique())\n",
        "\n",
        "counts = np.array([label_counts[label] for label in label_order], dtype=float)\n",
        "class_weights = 1.0 / counts\n",
        "class_weights = class_weights / class_weights.sum()\n",
        "\n",
        "# Keras expects a dictionary: {class_index: weight}\n",
        "class_index_mapping = {label: idx for idx, label in enumerate(label_order)}\n",
        "class_weights_dict = {class_index_mapping[label]: weight for label, weight in zip(label_order, class_weights)}\n",
        "\n",
        "print(class_weights_dict)\n"
      ],
      "metadata": {
        "id": "AeW_ox4G2_qh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f4b89f1-e842-4cd1-e8bf-1b17399c0c26"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: np.float64(0.1521780416341574), 1: np.float64(0.19177992966175975), 2: np.float64(0.21646447506376845), 3: np.float64(0.04193653193370962), 4: np.float64(0.07556305984368876), 5: np.float64(0.05053061320826028), 6: np.float64(0.11754253753462696), 7: np.float64(0.045706436198133686), 8: np.float64(0.041302730443527606), 9: np.float64(0.06699564447836756)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "DATA_DIR = \"/root/.cache/kagglehub/datasets/imbikramsaha/paddy-doctor/versions/1/paddy-disease-classification/train_images\"\n",
        "EPOCHS = 10\n"
      ],
      "metadata": {
        "id": "tPZ9Ej9UG73-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f260eebe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84941106-1e22-4520-ff09-6d78e4949ca4"
      },
      "source": [
        "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    DATA_DIR,\n",
        "    image_size=(224,224),\n",
        "    batch_size=32,\n",
        "    label_mode=\"int\",\n",
        "    validation_split=0.1,\n",
        "    subset=\"training\",\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "val_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    DATA_DIR,\n",
        "    image_size=(224,224),\n",
        "    batch_size=32,\n",
        "    label_mode=\"int\",\n",
        "    validation_split=0.1,\n",
        "    subset=\"validation\",\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "class_names = train_dataset.class_names\n",
        "\n",
        "# ✅ Print the class names in index order\n",
        "print(\"Class names in dataset (index order):\")\n",
        "print(class_names)\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10407 files belonging to 10 classes.\n",
            "Using 9367 files for training.\n",
            "Found 10407 files belonging to 10 classes.\n",
            "Using 1040 files for validation.\n",
            "Class names in dataset (index order):\n",
            "['bacterial_leaf_blight', 'bacterial_leaf_streak', 'bacterial_panicle_blight', 'blast', 'brown_spot', 'dead_heart', 'downy_mildew', 'hispa', 'normal', 'tungro']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the class names in index order\n",
        "print(\"Class names in model index order:\")\n",
        "print(train_dataset.class_names)\n"
      ],
      "metadata": {
        "id": "wDkgzAK3QAWf",
        "outputId": "bc5ddb85-004a-478d-9704-1cdca65dc0ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class names in model index order:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'_ParallelMapDataset' object has no attribute 'class_names'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4021111906.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Print the class names in index order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Class names in model index order:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: '_ParallelMapDataset' object has no attribute 'class_names'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "\n",
        "train_dataset = train_dataset.map(\n",
        "    lambda x, y: (preprocess_input(x), y),\n",
        "    num_parallel_calls=tf.data.AUTOTUNE\n",
        ")\n",
        "\n",
        "val_dataset = val_dataset.map(\n",
        "    lambda x, y: (preprocess_input(x), y),\n",
        "    num_parallel_calls=tf.data.AUTOTUNE\n",
        ")\n"
      ],
      "metadata": {
        "id": "oChpyPKgW6Is"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "360aa4ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0a8993b-1960-435a-9283-aa5e2ab8e278"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "label_counts = {i: 0 for i in range(len(class_names))}\n",
        "\n",
        "for _, labels in train_dataset.unbatch():\n",
        "    label_counts[int(labels.numpy())] += 1\n",
        "\n",
        "class_weights_dict = {\n",
        "    i: max(label_counts.values()) / count\n",
        "    for i, count in label_counts.items()\n",
        "}\n",
        "\n",
        "print(class_weights_dict)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 3.6492027334851938, 1: 4.711764705882353, 2: 5.322259136212624, 3: 1.0203821656050955, 4: 1.8287671232876712, 5: 1.237065637065637, 6: 2.907441016333938, 7: 1.132155477031802, 8: 1.0, 9: 1.638036809815951}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "num_classes = len(class_names)\n",
        "\n",
        "base_model = EfficientNetB0(\n",
        "    include_top=False,\n",
        "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "    weights='imagenet'\n",
        ")\n",
        "\n",
        "# ----------------------------\n",
        "# Step 1: Train head first\n",
        "# ----------------------------\n",
        "base_model.trainable = False  # freeze backbone\n",
        "\n",
        "inputs = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "x = base_model(inputs, training=False)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model = models.Model(inputs, outputs)\n",
        "\n",
        "# Compile for head training\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train head first\n",
        "history_head = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=5\n",
        ")\n",
        "\n",
        "# ----------------------------\n",
        "# Step 2: Fine-tune top layers\n",
        "# ----------------------------\n",
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:-20]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history_fine = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=5\n",
        ")\n"
      ],
      "metadata": {
        "id": "Oo7XMurL5vtO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cc3cd19-e188-4f8e-bfbc-452596fdfbe7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Epoch 1/5\n",
            "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 196ms/step - accuracy: 0.3790 - loss: 1.8031 - val_accuracy: 0.5712 - val_loss: 1.2669\n",
            "Epoch 2/5\n",
            "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 76ms/step - accuracy: 0.5632 - loss: 1.2814 - val_accuracy: 0.6567 - val_loss: 1.0695\n",
            "Epoch 3/5\n",
            "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 80ms/step - accuracy: 0.6211 - loss: 1.1384 - val_accuracy: 0.6615 - val_loss: 0.9923\n",
            "Epoch 4/5\n",
            "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 81ms/step - accuracy: 0.6581 - loss: 1.0493 - val_accuracy: 0.6990 - val_loss: 0.9214\n",
            "Epoch 5/5\n",
            "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 87ms/step - accuracy: 0.6636 - loss: 1.0004 - val_accuracy: 0.6981 - val_loss: 0.8789\n",
            "Epoch 1/5\n",
            "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 163ms/step - accuracy: 0.6186 - loss: 1.1484 - val_accuracy: 0.7971 - val_loss: 0.6226\n",
            "Epoch 2/5\n",
            "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 81ms/step - accuracy: 0.7856 - loss: 0.6844 - val_accuracy: 0.8538 - val_loss: 0.4612\n",
            "Epoch 3/5\n",
            "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 82ms/step - accuracy: 0.8427 - loss: 0.5116 - val_accuracy: 0.8837 - val_loss: 0.3658\n",
            "Epoch 4/5\n",
            "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 78ms/step - accuracy: 0.8839 - loss: 0.3822 - val_accuracy: 0.9029 - val_loss: 0.3062\n",
            "Epoch 5/5\n",
            "\u001b[1m293/293\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 81ms/step - accuracy: 0.9085 - loss: 0.3079 - val_accuracy: 0.9317 - val_loss: 0.2558\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# 1️⃣ Save the trained Keras model (optional)\n",
        "model.save(\"pest_disease_detection_model.h5\")  # HDF5 backup\n",
        "\n",
        "# 2️⃣ Convert to TensorFlow Lite\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "# Optional optimization\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# 3️⃣ Save as TFLite\n",
        "with open(\"pest_disease_detection_model.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(\"TFLite model saved as pest_disease_detection_model.tflite\")\n"
      ],
      "metadata": {
        "id": "Xp8DhZKHhIij",
        "outputId": "b642b2a3-2f22-48f9-e2c9-98139248bf8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved artifact at '/tmp/tmpc1kxzecs'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='keras_tensor_238')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  135642602129744: TensorSpec(shape=(1, 1, 1, 3), dtype=tf.float32, name=None)\n",
            "  135642602131664: TensorSpec(shape=(1, 1, 1, 3), dtype=tf.float32, name=None)\n",
            "  135642593165584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642593585552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642593433104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642593434832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642593176720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642593621776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642593611024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642593623312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642593621968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642593623696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642593621584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642593611408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642593623504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642593622544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602266000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602260048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602272528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602265424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602271952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602264272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602266576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602272912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602262352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602269840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602269072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602270992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602273680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602270608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602267920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602259856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602273488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602270224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602271376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602265040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602260240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602263504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602261008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602274064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602259472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602267536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602273872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602258704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602263312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602264464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602259280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602274448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602265808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602267344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602259088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602267152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602263696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602265232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602271184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602272144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602269264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602271760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602268880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602269648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602269456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602267728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602259664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602270416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602271568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602261584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602274640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602262736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602266768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602265616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602273104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602266192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602262160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602264656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602274256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602268496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602266384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602268112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602268304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602273296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602270032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602258512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602260432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602258896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642593556432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642593557584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602263120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642593551056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642593550288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642593542224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642593557008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642593551440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642593552208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601661328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601664016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642593542608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601666896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601657872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601665552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601665168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601660176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601654992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601661904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601664784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601655760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601656720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601652496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601659024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601654416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601656912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601661712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601658256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601655952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601664400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601654800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601663056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601662672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601658448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601656144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601659792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601656528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601658640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601655376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601652304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601666704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601667856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601657104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601665744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601663632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601660752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601660368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601658064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601653264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601660944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601660560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601653648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601662288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601666512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601667664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601655568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601659984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601656336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601661136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601663440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601665360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601659216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601668048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601662864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601667280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601652880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601666128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601668432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601652688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601659600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601668240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601653456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601664976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601654032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601666320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601657680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601661520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601665936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601655184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601654224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601667472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642601663824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602167504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602170192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602160976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602165392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602168656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602161168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602165776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602164816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602165968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602167696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602173072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602172688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602169424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602165008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602170960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602175376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602170384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602175952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602160208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602162320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602164624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602162512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602163280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602175568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602174224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602162704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602168080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602172880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602160592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602163472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602175184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602165200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602174608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602166928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602169232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602169808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602161936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602171920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602161360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602176336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602164048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602173648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602170000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602162128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602174992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602171344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602166352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602163088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602172496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602167888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602173456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602169040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602163856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602169616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602166736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602171152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602168464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602165584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602174032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602171536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602173840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602170768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602174416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602162896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602171728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602164432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602167312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602166544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602174800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602168848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602176144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602160784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602163664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602161744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602161552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602175760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602133392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602136656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602131280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602143184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602142608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602128400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602132240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602135120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602135504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602129936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602138768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602133584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602141264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602128976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602136272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602139152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602135696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642620931216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602128208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602129552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602132432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602142992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602134160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602142224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602141072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602137424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602136464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602139728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602137040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602133776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602129168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602139920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602133968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602135312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602138960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602133008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602134928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602129360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602140304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602140688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602138384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602140112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602128784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602138576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602139344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602141840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602131088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602130704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602142032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602131472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602137616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602140880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602143376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602130320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602136080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602127440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602141648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602142416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602140496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602130128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602127632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602138000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602132816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602142800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602137808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602127824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602132048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602134544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602130896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642602134736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135642593430992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "TFLite model saved as pest_disease_detection_model.tflite\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# 1️⃣ Load the TFLite model\n",
        "tflite_model_path = \"/content/pest_disease_detection_model.tflite\"\n",
        "interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# 2️⃣ Get input and output details\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "input_shape = input_details[0]['shape']\n",
        "print(f\"Model input shape: {input_shape}\")\n",
        "\n",
        "# 3️⃣ Function to predict a single image\n",
        "def tflite_predict(image):\n",
        "    # Resize and normalize image\n",
        "    img = tf.image.resize(image, (input_shape[1], input_shape[2]))\n",
        "    img = tf.expand_dims(img, axis=0)  # batch dimension\n",
        "    img = tf.cast(img, tf.float32) / 255.0  # normalization\n",
        "\n",
        "    interpreter.set_tensor(input_details[0]['index'], img.numpy())\n",
        "    interpreter.invoke()\n",
        "    output = interpreter.get_tensor(output_details[0]['index'])\n",
        "    return np.argmax(output, axis=1)[0]\n",
        "\n",
        "# Example usage:\n",
        "# pred_class = tflite_predict(some_image_tensor)\n",
        "# print(\"Predicted class index:\", pred_class)\n"
      ],
      "metadata": {
        "id": "pLQae_OQh6_-",
        "outputId": "dd72a8a6-e015-4ec3-ee8b-e5909d6c1c9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model input shape: [  1 224 224   3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
            "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
            "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
            "    for details.\n",
            "    \n",
            "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "\n",
        "def tflite_predict(image):\n",
        "    # Resize\n",
        "    img = tf.image.resize(image, (input_shape[1], input_shape[2]))\n",
        "    img = tf.expand_dims(img, axis=0)  # batch dimension\n",
        "    img = tf.cast(img, tf.float32)\n",
        "\n",
        "    # Use EfficientNet preprocessing\n",
        "    img = preprocess_input(img)\n",
        "\n",
        "    interpreter.set_tensor(input_details[0]['index'], img.numpy())\n",
        "    interpreter.invoke()\n",
        "    output = interpreter.get_tensor(output_details[0]['index'])\n",
        "    return np.argmax(output, axis=1)[0]\n"
      ],
      "metadata": {
        "id": "DxGrUCX7Qv2B"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Path to your image\n",
        "img_path = \"/content/100004.jpg\"\n",
        "\n",
        "# Load image\n",
        "img = tf.keras.preprocessing.image.load_img(img_path)\n",
        "img_tensor = tf.keras.preprocessing.image.img_to_array(img)\n",
        "\n",
        "# Run TFLite model inference\n",
        "pred_idx = tflite_predict(img_tensor)\n",
        "\n",
        "print(f\"Predicted class index: {pred_idx}\")\n"
      ],
      "metadata": {
        "id": "5oElZJTcO6ov",
        "outputId": "6427c8ea-b5e5-4001-86fb-33d453137efd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class index: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "from PIL import Image\n",
        "\n",
        "# ----- 1️⃣ Load TFLite model -----\n",
        "tflite_model_path = \"/content/pest_disease_detection_model.tflite\"\n",
        "interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "input_shape = input_details[0]['shape']\n",
        "\n",
        "# ----- 2️⃣ Define class names in the correct order -----\n",
        "class_names = [\n",
        "    'bacterial_leaf_blight',\n",
        "    'bacterial_leaf_streak',\n",
        "    'bacterial_panicle_blight',\n",
        "    'blast',\n",
        "    'brown_spot',\n",
        "    'dead_heart',\n",
        "    'downy_mildew',\n",
        "    'hispa',\n",
        "    'normal',\n",
        "    'tungro'\n",
        "]\n",
        "\n",
        "# ----- 3️⃣ Function to run inference and get raw outputs -----\n",
        "def tflite_predict_raw(image_path):\n",
        "    # Load image\n",
        "    img = Image.open(image_path).convert('RGB')\n",
        "    img = img.resize((input_shape[2], input_shape[1]))  # resize to model input\n",
        "    img = np.array(img, dtype=np.float32)\n",
        "\n",
        "    # Preprocess like EfficientNet\n",
        "    img = preprocess_input(img)\n",
        "    img = np.expand_dims(img, axis=0)  # add batch dimension\n",
        "\n",
        "    # Set tensor and invoke\n",
        "    interpreter.set_tensor(input_details[0]['index'], img)\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Get raw predictions\n",
        "    output = interpreter.get_tensor(output_details[0]['index'])[0]  # remove batch dim\n",
        "    return output\n",
        "\n",
        "# ----- 4️⃣ Run inference -----\n",
        "image_path = \"/content/100008.jpg\"\n",
        "raw_preds = tflite_predict_raw(image_path)\n",
        "\n",
        "# Print raw outputs\n",
        "print(\"Raw output probabilities/scores:\")\n",
        "for cls_name, score in zip(class_names, raw_preds):\n",
        "    print(f\"{cls_name}: {score:.4f}\")\n",
        "\n",
        "# Optional: predicted class\n",
        "pred_idx = np.argmax(raw_preds)\n",
        "print(f\"\\nPredicted class: {class_names[pred_idx]} (index {pred_idx})\")\n"
      ],
      "metadata": {
        "id": "I7mHxotkRdDy",
        "outputId": "a14c231e-4340-4a3e-d44d-f5fc3bc878bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw output probabilities/scores:\n",
            "bacterial_leaf_blight: 0.0079\n",
            "bacterial_leaf_streak: 0.0003\n",
            "bacterial_panicle_blight: 0.0016\n",
            "blast: 0.0007\n",
            "brown_spot: 0.0016\n",
            "dead_heart: 0.9217\n",
            "downy_mildew: 0.0004\n",
            "hispa: 0.0042\n",
            "normal: 0.0323\n",
            "tungro: 0.0292\n",
            "\n",
            "Predicted class: dead_heart (index 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
            "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
            "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
            "    for details.\n",
            "    \n",
            "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
          ]
        }
      ]
    }
  ]
}